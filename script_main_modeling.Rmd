---
title: "Modeling Portion of Capstone Project"
author: "Michael An"
date: "April 19, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caTools)
library(ROCR)
library(glmnet)

```


```{r, echo=FALSE}
source("/media/mike/UNTITLED/Foundations_Course/Capstone/exploratory_script_load.R")

#Attach computed statistics to c1045.as.column.centered variable as well


temp <- as.matrix(subset(c1045.as.column, subset = BrainMask != 0, select = ! names(c1045.as.column) %in% c("BrainMask", "ZStat", "ClusterMask", "corr.biological", "bio.rand.max.min.diff")))

stats.activities.bio <- apply(temp[,paradigm$Biological], 1, 
                              function(x) {
                                c(max = max(x),
                                  median = median(x),
                                  mean = mean(x),
                                  quantile90 = quantile(x,probs=.9),
                                  quantile80 = quantile(x,probs=.8),
                                  quantile70 = quantile(x,probs=.7))       
                                
                              })


temp <- as.matrix(subset(c1045.as.column, subset = BrainMask != 0, select = ! names(c1045.as.column) %in% c("BrainMask", "ZStat", "ClusterMask", "corr.biological", "bio.rand.max.min.diff")))


stats.activities.rand <- apply(temp[,paradigm$Random], 1, 
                              function(x) {
                                c(max = max(x),
                                  median = median(x),
                                  mean = mean(x),
                                  quantile90 = quantile(x,probs=.9),
                                  quantile80 = quantile(x,probs=.8),
                                  quantile70 = quantile(x,probs=.7))       
                                
                              })

temp <- data.frame(matrix(0, nrow = nrow(c1045.as.column), ncol = 6))
temp[c1045.as.column$BrainMask != 0,] <- t(stats.activities.bio - stats.activities.rand)
names(temp) <- c("bio.rand.max.min.diff", "bio.rand.median.diff",
                 "bio.rand.mean.diff", "bio.quantile90.diff",
                 "bio.quantile80.diff", "bio.quantile70.diff")

c1045.as.column <- cbind(c1045.as.column, temp)

c1045.as.column$corr.biological <- apply(c1045.as.column[,c(4:(nrow(paradigm)+3))],
                                         1, cor, paradigm$Biological)


c1045.as.column.centered$bio.quantile90.diff <- 
  c1045.as.column$bio.quantile90.diff
c1045.as.column.centered$bio.quantile80.diff <-
  c1045.as.column$bio.quantile80.diff
c1045.as.column.centered$bio.quantile70.diff <-
  c1045.as.column$bio.quantile70.diff
c1045.as.column.centered$corr.biological <- 
  c1045.as.column$corr.biological



temp <- as.matrix(subset(c1045.as.column.centered.2runs, subset = BrainMask != 0, select = ! names(c1045.as.column.centered.2runs) %in% c("BrainMask", "ZStat", "ClusterMask", "corr.biological", "bio.rand.max.min.diff")))

stats.activities.bio <- apply(temp[,paradigm.2runs$Biological], 1, 
                              function(x) {
                                c(max = max(x),
                                  median = median(x),
                                  mean = mean(x),
                                  quantile90 = quantile(x,probs=.9),
                                  quantile80 = quantile(x,probs=.8),
                                  quantile70 = quantile(x,probs=.7))       
                                
                              })


temp <- as.matrix(subset(c1045.as.column.centered.2runs, subset = BrainMask != 0, select = ! names(c1045.as.column.centered.2runs) %in% c("BrainMask", "ZStat", "ClusterMask", "corr.biological", "bio.rand.max.min.diff")))


stats.activities.rand <- apply(temp[,paradigm.2runs$Random], 1, 
                              function(x) {
                                c(max = max(x),
                                  median = median(x),
                                  mean = mean(x),
                                  quantile90 = quantile(x,probs=.9),
                                  quantile80 = quantile(x,probs=.8),
                                  quantile70 = quantile(x,probs=.7))       
                                
                              })

temp <- data.frame(matrix(0, nrow = nrow(c1045.as.column.centered.2runs), ncol = 6))
temp[c1045.as.column.centered.2runs$BrainMask != 0,] <- t(stats.activities.bio - stats.activities.rand)
names(temp) <- c("bio.rand.max.min.diff", "bio.rand.median.diff",
                 "bio.rand.mean.diff", "bio.quantile90.diff",
                 "bio.quantile80.diff", "bio.quantile70.diff")

c1045.as.column.centered.2runs <- cbind(c1045.as.column.centered.2runs, temp)

c1045.as.column.centered.2runs$corr.biological <- apply(c1045.as.column.centered.2runs[,c(4:(nrow(paradigm.2runs)+3))],
                                         1, cor, paradigm.2runs$Biological)
```

###Fitting a simple logistic model

In this analysis, we utilize the centered fMRI time activity points, as well as the summary statistics derived in the EDA section, as our predictors. The response is the activation state binary outcome. The data is collected for only one subject. There are some dangers in doing this, but this is our preliminary modeling for this project, and we discuss potential points to be aware of in our analysis. The voxel data is divided into training and test set, with a split of 25% of voxels used as training, the rest as test. A low ratio of training voxels is plausible here due to a high number of voxels as observations (70320). 
```{r, echo=FALSE}
#Set generic names for the data, so you dont change the originals
subject.image.mask <- c1045.mask
model.data <- subset(c1045.as.column.centered, BrainMask != 0)
model.data$ClusterMaskBinary <- model.data$ClusterMask > 0
model.paradigm <- paradigm



data.split.bool <- sample.split(model.data$ClusterMaskBinary, SplitRatio = .25)

data.train <- subset(model.data, data.split.bool = TRUE)
data.test <- subset(model.data, data.split.bool = FALSE)
```

First, we run the non-regularized logistic regression model with the predictors and response just described.
```{r}
#Logistic regression model


ActivationModel <- glm(ClusterMaskBinary ~ . - BrainMask - ZStat - ClusterMask - ClusterMaskBinary , data = data.train, family = binomial)

predictionTrain <- predict(ActivationModel, type="response" )

tapply(predictionTrain, data.train$ClusterMaskBinary, mean)

summary(ActivationModel)
```
Looking at the results, we see that only a few of the predictors are significant. We note first that the correlation coefficient (last variable) to the biological motion task is highly significant. The other summary statistics that we added from performing EDA, are not as significant, or not significant. More importantly, most of the time activity points as predictors, are not significant.

One thing to suspect is the covariance relationship between the time activity points and the correlation coefficients, and how the resulting multicollinearity of the predictors may affect significance. To asses this with respect to correlation coefficient, we drop this predictor as a covariate and rerun the model fit.


```{r}
#Logistic regression model


ActivationModel <- glm(ClusterMaskBinary ~ . - BrainMask - ZStat - ClusterMask - ClusterMaskBinary - corr.biological, data = data.train, family = binomial)

predictionTrain <- predict(ActivationModel, type="response" )

tapply(predictionTrain, data.train$ClusterMaskBinary, mean)

summary(ActivationModel)
```

As we suspected, the resulting model weighs signficance to many of the time activity points now. Since we want to use time activity points preferentially to predict activation because it doesn't involve knowledge of the event paradigms, we prefer this model. 
To take a closer look at the time activity points as predictors, we take a look at where each time point lies with respec to the design paradigm. Specifically, we threshold the Z Stat for each predictor at a 95% confidence, and show the corresponding biological and random motion event timing together with the thresholded values.

```{r, echo=FALSE}

#assess z stats of coefficients corresponding to time activity paradigm
model.paradigm$pval <- coef(summary(ActivationModel))[,4][2:(nrow(model.paradigm)+4-3)] < 5e-2
```
We can see here that the significant points along the time activity curve are the points in time when the biological motion task was applied.

Next, we use our model to predict activation. First, we generate an ROC curve to determine a good threshold value for which to threshold our response variable. Here, the priorirty is to minimize the false positive rate as much as possible while maintaining an acceptible true positive rate. 
```{r}
# confuse.matrix <- table(data.train$ClusterMaskBinary, predictionTrain > .3)
# 
# #sensitivity - true positive rate
# confuse.matrix[2,2]/(confuse.matrix[2,1]+confuse.matrix[2,2])
# 
# #specificity - true negative rate
# confuse.matrix[1,1]/(confuse.matrix[1,1]+confuse.matrix[1,2])

#Use ROCR library to plot ROC curve
cluster.pred <- prediction(predictionTrain, model.data$ClusterMaskBinary)
perform.func <- performance(cluster.pred, "tpr", "fpr")

plot(perform.func, print.cutoffs.at=seq(.1,.9,.1))
```
We see that a thresold value of .3 would work best.
Now we asses the model by predicting activation of the combined training and test set at the threshold we determined. To do this we take a look at the confusion matrix.

```{r}

#verify model by predicting the combined training and test set
predictionTest <- predict(ActivationModel, type="response", newdata = model.data)

confuse.matrix <- table(model.data$ClusterMaskBinary,
                        predictionTest > .3)

#sensitivity - true positive rate
confuse.matrix[2,2]/(confuse.matrix[2,1]+confuse.matrix[2,2])

#specificity - true negative rate
confuse.matrix[1,1]/(confuse.matrix[1,1]+confuse.matrix[1,2])
```

We have good sensitivity and specificity here. 



```{r, echo=FALSE}
#create test cluster image based on the given prediction threshold

prediction.all <- predict(ActivationModel, type="response", 
                          newdata = model.data)

#reference Nifti object to put out new mask into
nifti.prediction.mask <- c1045.cluster.mask

#create new space to put in the mask in image space
#using the BrainMask > 0 mask
temp <- array(0, dim = dim(nifti.prediction.mask@.Data))
temp[subject.image.mask@.Data > 0] <- as.integer( prediction.all > .3 )

#insert the data into the nifti object's .Data field 
nifti.prediction.mask@.Data <- temp
```

To visually compare the activation classification results of the logistic regression model to our group wise activation generated from standard GLM, we overlay the activation regions that we predicted in our model onto the MNI standard brain.
```{r}
#write and save resulting maps

#writeNIfTI(nifti.prediction.mask, "c1045_logistic_classific_map", onefile=TRUE)

#View the resulting image and mask
overlay(c1045, ifelse(nifti.prediction.mask == 0, NA, nifti.prediction.mask), col.y = heat.colors(1))


```

We do the same for the the group wise activation from GLM:
```{r}
overlay(c1045, ifelse(c1045.cluster.mask ==0, NA, 1),col.y=heat.colors(1))

```
Visually (i.e. qualitatively speaking), the overall patterns are similar. As we saw before, the sensitivity is around ?????, so we get less activated voxels compared to the group wise map. However, the images still suggest similar areas of activation in the brain associated with greater biological motion task response vs random motion task response. For example, we still see large regions of activation in the superior temporal region (STS), inferior frontal region (IFG), prefrontal cortex (PFC). 



To recall, our main goal was to assess the performance of the model with less runs, or time points. We apply the same analysis as above, but using only 2 run's time points as predictors.



```{r, echo=FALSE}
#Set generic names for the data, so you dont change the originals
model.data <- subset(c1045.as.column.centered.2runs, BrainMask != 0)
model.data$ClusterMaskBinary <- model.data$ClusterMask > 0
model.paradigm <- paradigm.2runs

data.split.bool <- sample.split(model.data$ClusterMaskBinary, SplitRatio = .25)

data.train <- subset(model.data, data.split.bool = TRUE)
data.test <- subset(model.data, data.split.bool = FALSE)
```

The Model Summary:
```{r}
#Logistic regression model


ActivationModel <- glm(ClusterMaskBinary ~ . - BrainMask - ZStat - ClusterMask - ClusterMaskBinary - corr.biological, data = data.train, family = binomial)

predictionTrain <- predict(ActivationModel, type="response" )

summary(ActivationModel)
```
Our ROC Curve:
```{r}

#Use ROCR library to plot ROC curve
cluster.pred <- prediction(predictionTrain, model.data$ClusterMaskBinary)
perform.func <- performance(cluster.pred, "tpr", "fpr")

plot(perform.func, print.cutoffs.at=seq(.1,.9,.1))
```
A quick look at the confusion matrix:
```{r}

#verify model by predicting the combined training and test set
predictionTest <- predict(ActivationModel, type="response", newdata = model.data)

confuse.matrix <- table(model.data$ClusterMaskBinary,
                        predictionTest > .3)

#sensitivity - true positive rate
confuse.matrix[2,2]/(confuse.matrix[2,1]+confuse.matrix[2,2])

#specificity - true negative rate
confuse.matrix[1,1]/(confuse.matrix[1,1]+confuse.matrix[1,2])
```


```{r, echo=FALSE}
#create test cluster image based on the given prediction threshold

prediction.all <- predict(ActivationModel, type="response", 
                          newdata = model.data)

#reference Nifti object to put out new mask into
nifti.prediction.mask <- c1045.cluster.mask

#create new space to put in the mask in image space
#using the BrainMask > 0 mask
temp <- array(0, dim = dim(nifti.prediction.mask@.Data))
temp[subject.image.mask@.Data > 0] <- as.integer( prediction.all > .3 )

#insert the data into the nifti object's .Data field 
nifti.prediction.mask@.Data <- temp
```

The resulting activation map:
```{r}
#write and save resulting maps

#writeNIfTI(nifti.prediction.mask, "c1045_logistic_classific_map", onefile=TRUE)

#View the resulting image and mask
overlay(c1045, ifelse(nifti.prediction.mask == 0, NA, nifti.prediction.mask), col.y = heat.colors(1))


```

Again, compared to our group activation map from standard fMRI analysis:
```{r}
overlay(c1045, ifelse(c1045.cluster.mask ==0, NA, 1),col.y=heat.colors(1))

```
If we compare the results here with the results that we got from using all the runs, the degredation in performance is not severe. There is a marked difference in that most of the time activity points in this model are significant. While we cannot be sure, this may be due to some runs having more salient features/time points for which better descriminates activation. In terms of the sensitivity, it is similar to the full run data, with a bit lower specificity, which means that less points will accurately be classified as active.  Indeed, a visual inspection indicates that this is the case, though we can still see activation in the main regions of interest.


To analyze further the effect of modeling activation over a subset of available time activity information, we also fit a LASSO logistic regression model to the full run data.
### LASSO Logistic Regression Portion 

```{r, echo=FALSE}
#Set generic names for the data, so you dont change the originals
subject.image.mask <- c1045.mask
model.data <- subset(c1045.as.column.centered, BrainMask != 0)
model.data$ClusterMaskBinary <- model.data$ClusterMask > 0
model.paradigm <- paradigm

data.split.bool <- sample.split(model.data$ClusterMaskBinary, SplitRatio = .25)

data.train <- subset(model.data, data.split.bool = TRUE)
data.test <- subset(model.data, data.split.bool = FALSE)
```


<!-- ```{r} -->
<!-- lasso.model.data.pred.train <- model.matrix(ClusterMaskBinary ~ . - BrainMask - ZStat - ClusterMask - ClusterMaskBinary - corr.biological , data = data.train)[,-1] -->
<!-- lasso.model.data.y.train <- data.train$ClusterMaskBinary -->

<!-- lasso.model.data.pred.test <- model.matrix(ClusterMaskBinary~.- BrainMask - ZStat - ClusterMask - ClusterMaskBinary - corr.biological , data=data.test)[,-1] -->
<!-- lasso.model.data.pred.test <- data.test$ClusterMaskBinary -->

<!-- grid <- 10^seq(10,-2,length=100) -->
<!-- lasso.train <- glmnet(lasso.model.data.pred.train,lasso.model.data.y.train -->
<!--                       ,family="binomial", alpha=1, lambda=grid) -->
<!-- dim(coef(lasso.train)) -->

<!-- set.seed(123) -->
<!-- cv.out <- cv.glmnet(lasso.model.data.pred.train,lasso.model.data.y.train, -->
<!--                    alpha=1,family="binomial", nfolds =  -->
<!--                      floor(length(lasso.model.data.y.train)/2)) -->
<!-- plot(cv.out) -->
<!-- bestlam <- cv.out$lambda.min -->
<!-- #bestlam <- cv.out$lambda.1se -->

<!-- # Training Accuracy -->
<!-- train.lasso <- predict(lasso.train, s=bestlam, newx=lasso.model.data.pred.train, type="class") -->

<!-- confuse.matrix <- table(lasso.model.data.y.train,train.lasso)  -->

<!-- confuse.matrix -->

<!-- #sensitivity - true positive rate -->
<!-- confuse.matrix[2,2]/(confuse.matrix[2,1]+confuse.matrix[2,2]) -->

<!-- #specificity - true negative rate -->
<!-- confuse.matrix[1,1]/(confuse.matrix[1,1]+confuse.matrix[1,2]) -->


<!-- # #Use ROCR library to plot ROC curve -->
<!-- # #DOESNT WORK, prediction function needs PROBABILITIES of belonging to class 1, -->
<!-- # #NOT A PREDICTED LABEL. CAN YOU GET THIS WITH LASSO? -->
<!-- # cluster.pred <- prediction(ifelse(train.lasso == "TRUE", 1, 0), -->
<!-- #                            data.train$ClusterMaskBinary) -->
<!-- # pred.perform.func <- performance(cluster.pred, "tpr", "fpr") -->
<!-- #  -->
<!-- # plot(pred.perform.func, print.cutoffs.at=seq(.1,.9,.1)) -->


<!-- # Test Accuracy -->
<!-- lasso.pred <- predict(lasso.train, s=bestlam, newx=lasso.model.data.pred.test, type="class") -->

<!-- confuse.matrix <- table(lasso.pred, lasso.model.data.y.test)  -->

<!-- confuse.matrix -->

<!-- #sensitivity - true positive rate -->
<!-- confuse.matrix[2,2]/(confuse.matrix[2,1]+confuse.matrix[2,2]) -->

<!-- #specificity - true negative rate -->
<!-- confuse.matrix[1,1]/(confuse.matrix[1,1]+confuse.matrix[1,2]) -->

<!-- ``` -->


<!-- #create test cluster image based on the given prediction threshold -->
<!-- ```{r} -->
<!-- prediction.all <- predict(lasso.train, s=bestlam, newx=model.matrix(ClusterMaskBinary~.- BrainMask - ZStat - ClusterMask - ClusterMaskBinary , data=model.data)[,-1] -->
<!--                           , type="class") -->

<!-- #reference Nifti object to put out new mask into -->
<!-- nifti.prediction.mask <- c1045.cluster.mask -->

<!-- #create new space to put in the mask in image space -->
<!-- #using the BrainMask > 0 mask -->
<!-- temp <- array(0, dim = dim(nifti.prediction.mask@.Data)) -->
<!-- temp[subject.image.mask@.Data > 0] <- ifelse(prediction.all == "TRUE", 1, 0) -->

<!-- #insert the data into the nifti object's .Data field  -->
<!-- nifti.prediction.mask@.Data <- temp -->
<!-- ``` -->



<!-- #write and save resulting maps -->
<!-- ```{r} -->
<!-- writeNIfTI(nifti.prediction.mask, "c1045_lasso_classific_map", onefile=TRUE) -->

<!-- par(mfrow = c(2,1)) -->
<!-- #View the resulting image and mask -->
<!-- overlay(c1045, ifelse(nifti.prediction.mask == 0, NA, nifti.prediction.mask), col.y = heat.colors(1)) -->
<!-- overlay(c1045, ifelse(c1045.cluster.mask ==0, NA, 1),col.y=heat.colors(1)) -->


<!-- ``` -->